---
title: "Preparing Data for Constructing Diversification Measures (eg, MS = 1 if a multiple-segment firm)"
output:
  html_notebook: default
  # html_document: default
  # word_document: default
---

This code prepares a sample for replicating some diversification discount results in Table III
of Custodio (2014) using data for 1990-1991.

She constructs her sample based on the following criteria:

* firms with missing segment SIC codes are excluded

* firms must *NOT* have any [*business* segment] in the 
  - financial sector (SIC codes 6000 to 6999), 
  - agriculture (SIC code lower than 1000), 
  - government (SIC 9000), or 
  - other noneconomic activities (SIC 8600 and 8800)

In addition,  

* firms for unclassified services (SIC 8900) are excluded; 
  
* firm sales greater than $20 million; 

* firms for which the [sum of business segment sales or assets] deviates from the [firm’s total sales or assets] by [more than 5%] are also excluded


# Load required library and set changeable parameters
```{r}

# '#' indcates the beginning of a comment (ignored by R) to annotate code lines
# It is also a convenient way to deactivate a code line when you change your mind and want to exclude it


# Below loads the required libraries
#library(magrittr)
library(tidyverse)
library(lubridate)

segmData_file = 'compsegd_1990_1991.csv'
firmData_file = 'ccmfunda_01Jan1990_31Dec1991.csv'


# Below sets changeable parameters for the path of the cleaned data file
mainDir = ''  
subDir = ''  

```


#------------------------------------------------------------------------------------
# Commands and functions used in the next code chunk: 

'paste0(TextString1, TextString2)' combines the texts in the two text string variables into one single text string

'%>%' is used to chain a series of operations together in one go (a function by package {magrittr})
 You can think of the chained operations as the different steps in a factory production line

'mutate(Variable = Value)' assigns a value to a column variable of a dataframe

'datadate' is Compustat's variable for the date of the data in concern. 

'ymd(VariablewithValueLikeADate)' turns a text string or integer variable with a value that looks like a date into R's date format, eg, 19901231 as an integer into 1990-12-31, a value of the date type in R. 

'tolower(names(Dataframe_L))' converts all the column variable names of the dataframe to lower case

#------------------------------------------------------------------------------------

# Read in raw segment-level data, followed by prelim preparations
```{r}

segmData <- read.csv(paste0(mainDir, subDir, segmData_file)) %>% 
    mutate(
      datadate_int = datadate, # keep a copy of the original integer format
      srcdate_int = srcdate,
      datadate = ymd(datadate), # convert to Date format
      srcdate = ymd(srcdate),
      ) %>% 
    mutate(dyear = year(datadate), dmonth = month(datadate), dday = day(datadate),
           syear = year(srcdate), smonth = month(srcdate), sday = day(srcdate),
           ) %>% 
    select(everything()) 

# change all column variable names to lowercase
names(segmData) <- tolower(names(segmData))

```


#------------------------------------------------------------------------------------
# Commands and functions used in the next code chunk: 

'is.na(Variable)' checks whether T or F that the Variable has no value (ie, indicated as NA)

'rm_flag' below sets the flag for later removing certain inappropriate observations
  It is only indicating what is to be removed, not immediately removing the observation
 Certain observations need to be reomoved because they do not fit the sample construction criteria

'sics_my' below is my version of the segment SIC code,
  currently defined as sics_my = sics1 (the first segment SIC code provided by Compustat)
Coding in terms of sics_my allows the flexibility of changing the assignment of sics_my later
For example, I can simply reassign sics_my = sics2 (Compustat's second segment SIC code)
  without changing all the code lines involving sics_my

'ifelse(Condition, Value_T, Value_F)' checks
  whether the Condition is true (T) or false (F) for every item in a column of a dataframe
  (or, if you like, a worksheet),
  then assign Value_T if the condition is true and Value_F if false

'=>' means greater than or equal to ('==' means equal to, '<=' means less than or equal to)

'group_by(Var1, Var2, Var3)' groups the rows of a dataframe according to
  each unique combination of the variables Var1, Var2, and Var3,
  then let the actions in the code lines thereafter to apply the actions group by group individually,
  eg, this would be convenient for computing the subtotals of those groups,
  rather than a single overall for all the rows of the dataframe.
  
'gvkey' is Compustat's unique company identifier for each firm in the database (Note: the variable gvkey from the CRSP-Compustat Merged Fundamental Annual database was originally in captial letters, ie, GVKEY. It must be converted into lower case before it can be used as the key for merging the firm-level Fundamental Annual data with the segment-level Historical Segments data)

'ungroup()' ends the group operations and returns to the normal mode

'|' means the OR of two conditions ('&' means the AND of two conditions)

'!' placed in front of a logical variable (taking TRUE or FALSE as value) means negation, ie,
 turning TRUE to FALSE, or FALSE to TRUE
 thus, '!rm_flag' stands for the condition that !rm_flag is TRUE, which means rm_flag is FALSE

'filter(Condition)' filters the dataframe to keep only the rows in the dataframe meeting the Condition
  So 'filter(!rm_flag)' keeps only the rows where the flag rm_flag = FALSE

#------------------------------------------------------------------------------------

# Data integrity checks: Remove problematic observations (e.g., from prelim releases), standardize data, apply filtering criteria, etc
```{r}

segmData <- segmData %>% 
  #=========================================================
  # upds = 2 means newswire, incomplete, trading suspended, etc; = 1 means only market data, csho 
  filter(upds == 3 & !is.na(upds)) %>% # = 3 means final
############################################################### <--------------------------------- !!!  
  mutate(rm_flag = FALSE) %>% # set initial value of rm_flag (ie, by default, do not remove)
################################################################################################
  mutate(snms = tolower(snms)) %>% # standardize segment name to lowercase
  # convert sics's to integer type to be consistent with sich
  mutate_at(vars(starts_with("sics")), ~ as.integer(.)) %>%  
  # Create sics_my to allow for the possibility of later classifying undesirable cases into
  #   negative-value categories (eg, -6666 for "undesirable" financial segment)
  mutate(sics_my = sics1) %>% 
  ################################################################################################
  # remove gvkey-datadate obs with unwanted segment SIC's by first setting unwanted sics_my to NA
  mutate(sics_my = ifelse((sics_my >= 6000 & sics_my <= 6999) 
                          | (sics_my >= 0000 & sics_my <= 1000)
                          | sics_my == 9000
                          | sics_my == 8600 | sics_my == 8800  
                          , NA, sics_my)) %>%   # need to set to NA in order to use anyNA() later
  mutate(rm_flag = FALSE) %>% # set initial value of rm_flag (ie, by default, do not remove)
  group_by(
    stype, gvkey, datadate
    ) %>% 
  ########################################################## <------------------------------ !!! 
  # Custodio said to have removed all obs with any missing-value sics1 or unwanted sics_my
  mutate(rm_flag = ifelse(sum(is.na(sics1)|is.na(sics_my)) > 0, TRUE, FALSE)) %>% 
  ##########################################################  
  ungroup() %>% 
  filter(!rm_flag) %>% 
  select(everything())  

```


# Data integrity checks: Prelim look of categorical data and summary of continuous variables
```{r}

facVars <- "dmonth, smonth, dday, sday, srcs, upds, stype, sid, soptp1, soptp2, geotp, curcds, isosrc" %>%  
  str_split(", ", simplify = TRUE) %>% 
  c()

# Prelim look of various categorical variables
segmData %>% 
  # turn the following into factors only for the purpose of examining the categorical and continuous variables
  mutate_at(vars(facVars), ~ as.factor(.)) %>% 
  select(datadate, srcdate, 
         dyear, syear, dmonth, smonth, dday, sday, 
         srcs, upds, stype, sid, 
         rm_flag, soptp1, soptp2, geotp, curcds, isosrc
         ) %>% 
  summary()


cat("\n\nsummary of continuous variables:\n\n")
segmData %>%
  select(-facVars) %>% 
  select_if(is.numeric) %>%
  summary() %>% 
  print()

```


# Data integrity checks: Confirm no duplicate segment ID (sid) for each gvkey-datadate (or gvkey-dyear-dmonth)
```{r}

# no duplicate for each (gvkey, datadate, sid)
segmData %>% 
  group_by(gvkey, datadate, sid) %>% 
  filter(n() > 1) %>% 
  nrow() 
# Expecting 0 found 


# no duplicate for each (gvkey, dyear, dmonth, sid)
segmData %>% 
  group_by(gvkey, dyear, dmonth, sid) %>% 
  filter(n() > 1) %>% 
  nrow() 
# Expecting 0 found 


#==========================================================
# any duplicates for each (gvkey, [dyear], sid) due to change of FYE or segment name/structure?
segmData %>% 
  group_by(
    stype,  
    gvkey, dyear, sid) %>% 
  filter(n() > 2) %>%
  nrow()
# Expecting 0 found for n() > 2 (assuming n() = 2 caused by change of FYE only)

# !!! Note: There may still be duplicates due to change of FYE to be taken care of later.

```


#------------------------------------------------------------------------------------
# Commands and functions used in the next code chunk: 

'n()' gets the total count of the rows in a group;
  eg, used to determine how many segments a firm has (after grouping segment records by each firm)

'sum(Variable)' gets the total sum of the values in the Variable column of a group
  eg, used to determine the sum of the segment sales of a firm
  For financial reporting reasons, this sum can deviate from the consolidated total sales of the firm
  Diversification research often requires excluding obs. with large deviations in firm & segment sales

ias refers to the Compustat variable 'Identifiable Assets - Segment'
see https://wrds-web.wharton.upenn.edu/wrds/support/Data/_001Manuals%20and%20Overviews/_001Compustat/_001North%20America%20-%20Global%20-%20Bank/_000dataguide/ias.cfm

'arrange(Var1, Var2, Var3)' sorts the dataframe in ascending order by the variables Var1, Var2, Var3
 Use 'desc(Variable)' to indicate that this Variable is to be sorted by descending order

Anything embraced by opening " and closeing " is a text string
'as.integer("8")' will convert the text string "8" into a variable of the integer type with a value 8
'as.integer(TRUE)' will convert the logical value TRUE to integer 1 (FALSE will be converted to  0)

#------------------------------------------------------------------------------------

# Compute the number of segments, segment sums, and segment weights

```{r}

segmData <- segmData %>% 
  #=======================================================
  # compute nseg = number of segments, MS = 1 if nseg > 1
  group_by(
    stype, gvkey, datadate
    ) %>% 
  mutate(nseg = n(),
         saleSUM = sum(sales),
         iaSUM = sum(ias),
         # compute each segment's weight as a fraction of the sum of all segment sales (or segment assets)
         w_sales = sales/saleSUM,
         w_ias = ias/iaSUM,
         ) %>% 
  ungroup() %>% 
  # define dummy for multiple-segment firms
  mutate(MS = as.integer(nseg > 1)) %>% 
  arrange(desc(nseg), gvkey, stype, datadate, sid) %>% 
  select(everything())

```


# Read in raw firm-level data, remove problematic observations (e.g., from prelim releases), standardize data, apply filtering criteria, etc
```{r, eval=T}

# Read in firm-level data and apply filtering criteria
firmData <- read.csv(paste0(mainDir, subDir, firmData_file), 
                   stringsAsFactors = FALSE) %>% 
# convert datadate to Date format
  mutate(
    datadate_int = datadate, # keep a copy of the original integer format
    datadate = ymd(datadate), 
    dyear = year(datadate), dmonth = month(datadate), dday = day(datadate),
    ) %>% 
# For simplicity, keep only the security issue ID '01' so that 
#   there is only one issue for each firm in the sample to avoid any complication
  filter(LIID == "1") %>% 
# remove ADR firms (ie, firms with non-empty ADR ratio) and firms incorporated outside USA
  filter(is.na(adrr) & fic == "USA") %>% 
# keep only firm-level data from 12-month accounting period
  filter(pddur == 12) %>% 
# keep only final data
  filter(upd == 3 & !is.na(upd)) %>% # = 3 means final
# upd = 2 means newswire, incomplete, trading suspended, etc; = 1 means only market data, csho 
  # apply Custodio's criterion: sale >= 20 million
  filter(sale > 20) %>%  
  # The next is implicitly required to implement the "no larger than 5% deviation" criteria
  # because at is to be used as the base and hence has to be positive
  filter(at > 0) %>% 
#########################################  
  # apply Custodio's criterion:
  filter(sich != 8900) %>%   
  select(everything()) 


# change all column variable names to lowercase
names(firmData) <- tolower(names(firmData))  

```


# Data integrity checks: Confirm no duplicate gvkey for each datadate (or dyear-dmonth or dyear)
```{r}

# no duplicate for each (gvkey, datadate)
firmData %>% 
  group_by(gvkey, datadate) %>% 
  filter(n() > 1) %>% 
  nrow() 
# Expecting 0 found 


# no duplicate for each (gvkey, dyear, dmonth)
firmData %>% 
  group_by(gvkey, dyear, dmonth) %>% 
  filter(n() > 1) %>% 
  nrow() 
# Expecting 0 found 


# no duplicate for each (gvkey, dyear)
firmData %>% 
  group_by(gvkey, dyear, dmonth) %>% 
  filter(n() > 1) %>% 
  nrow() 
# Expecting 0 found 

```


#------------------------------------------------------------------------------------
# Commands and functions used in the next code chunk: 

'Dataframe_L %>% select(Var1, Var2, Var3)', or equivalently 'select(Dataframe_L, Var1, Var2, Var3)', 
  selects to keep only the Var1, Var2, Var3 columns of the dataframe
  'select(Var1, everything())' moves Var1 to the beginning column of the dataframe and 
  still keeps everything else in the dataframe

'Dataframe_L %>% left_join(Dataframe_R, by = c("Var1", "Var2"))' merges all the variable columns in Dataframe_R to Dataframe_L by the merging key variables Var1 and Var2, keeping all the rows in Dataframe_L (and potential expanding the rows if the rows between the two dataframes do not match uniquely). 

#------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------
To apply the filtering criterion below, segment-level data are merged into firm-level data to provide the sums of segment sales and segment assets (saleSUM and iaSUM): 

  * firms for which the [sum of business segment sales or assets] deviates from the [firm’s total sales or assets] by [more than 5%] are also excluded

Applying the criterion removes the firms that involve larger than acceptable deviations between firm and segment sales or assets, excluding these problematic cases from the sample.  

#------------------------------------------------------------------------------------

# Match segment data to firm data and retain only records with distinct gvkey-dyear 

```{r}

# Remove duplicated segment records in the same calendar year
segmData_clean <- segmData %>%
        ##################################################
        # sort by gvkey, sid, and desc(datadate)
        arrange(gvkey, sid, desc(datadate)) %>%
        # keep only rows with distinct gvkey-sid-dyear
        distinct(gvkey, sid, dyear, .keep_all = TRUE) %>%
        # Note: The above ensures that only the latest of multiple segment records in the same calendar year is retained.
        #   The situation can occur under various circumstances, such as a change in fiscal year end leading to
        #   two consecutive accounting periods ending in different months of the same calendar year
        ####################################################
  select(everything())


# Turn segment data into firm-centric, keeping only one line of segment sums information for each firm 
#   (thus, become firm-level after this operation)
segmData_sums <- segmData_clean %>% 
      select(gvkey, datadate, dyear, 
             saleSUM, iaSUM,
             nseg, MS, 
             ) %>% 
      # sort by gvkey and desc(datadate)
      arrange(gvkey, desc(datadate)) %>%
      # keep only rows with distinct gvkey-dyear
      distinct(gvkey, dyear, .keep_all = TRUE)


# Merge to firm-level data the saleSUM and iaSUM variables and exclude firms where firm sales (or total assets) are much larger than the sum of the firm's segment sales (or segment assets)
firmData_clean <- firmData  %>% 
  left_join(
    segmData_sums, 
    by = c("gvkey", "dyear", "datadate")) %>% 
          # apply Custodio's criterion: deviation in firm sale (or at) from the segment sum <= 5%
          filter(abs(1 - saleSUM/sale) <= 0.05) %>%
          filter(abs(1 - iaSUM/at) <= 0.05) %>%
  select(everything())


# Similarly, remove segments from firms with large deviations from segment sums
segmData_clean <- segmData_clean %>%
#segmData_new <- segmData_clean %>%
                left_join(
                  firmData_clean %>%
                    select(gvkey, datadate, dyear, sale, at),
                  by = c("gvkey", "dyear", "datadate")) %>% 
          # apply Custodio's criterion: deviation in firm sale (or at) from the segment sum <= 5%
          filter(abs(1 - saleSUM/sale) <= 0.05) %>%
          filter(abs(1 - iaSUM/at) <= 0.05) %>%
  select(everything())

```


# Save cleaned data for further processing and regression analysis
```{r}

saveRDS(segmData_clean, file = paste0(mainDir, subDir, "segmentHist_clean", 'Example.rds'))
saveRDS(firmData_clean, file = paste0(mainDir, subDir, 'firm_clean', 'Example.rds'))

```

